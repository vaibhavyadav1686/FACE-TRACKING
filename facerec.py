#importing necessary modules
import face_recognition
import os
import cv2
import pickle
import time
from threading import Thread
import datetime


# We can use multithreading to help boost the facial recognition process
# In my case, the output file generated by this method was around 2 times as fast.

# defining the helper class for implementing multi-threading 
class WebcamStream :
    # initialization method 
    def __init__(self, stream_id=0):
        self.stream_id = stream_id # default is 0 for main camera 
        
        # opening video capture stream 
        self.vcap      = cv2.VideoCapture(self.stream_id)
        self.vcap.set(cv2.CAP_PROP_BUFFERSIZE, 2)
        if self.vcap.isOpened() is False :
            print("[Exiting]: Error accessing webcam stream.")
            exit(0)
        fps_input_stream = int(self.vcap.get(5)) # hardware fps
        print("FPS of input stream: {}".format(fps_input_stream))
            
        # reading a single frame from vcap stream for initializing 
        self.grabbed , self.frame = self.vcap.read()
        if self.grabbed is False :
            print('[Exiting] No more frames to read')
            exit(0)
        # self.stopped is initialized to False 
        self.stopped = True
        # thread instantiation  
        self.t = Thread(target=self.update, args=())
        self.t.daemon = True # daemon threads run in background 
        
    # method to start thread 
    def start(self):
        self.stopped = False
        self.t.start()
    # method passed to thread to read next available frame  
    def update(self):
        while True :
            if self.stopped is True :
                break
            self.grabbed , self.frame = self.vcap.read()
            if self.grabbed is False :
                print('[Exiting] No more frames to read')
                self.stopped = True
                break 
        self.vcap.release()
    # method to return latest read frame 
    def read(self):
        return self.frame
    # method to stop reading frames 
    def stop(self):
        self.stopped = True







# Known faces directory: where known faces shall be stored
# In some cases you might have to provide the entire path for the directory
KNOWN_FACES_DIR = "known_faces"

# Tolerance level setting - can be manipulated to implement a more crtical model
TOLERANCE = 0.6


FRAME_THICKNESS = 3
FONT_THICKNESS = 2

# model to be used
MODEL = "cnn" #or hog

# Taking the video input (you may have to provide the entire path for the video file)
video = cv2.VideoCapture("stockvideo.mp4")


frame_width = int(video.get(3))
frame_height = int(video.get(4))
 
# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.
out = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))


print("loading known faces")
known_faces = []
known_names = []

# Loading any known faces from the KNOWN_FACES_DIR
for name in os.listdir(KNOWN_FACES_DIR):
    for filename in os.listdir(f"{KNOWN_FACES_DIR}/{name}"):
        encoding = pickle.load(open(f"{name}/{filename}","rb"))
        known_faces.append(encoding)
        known_names.append(int(name))


# setting beginning ID
if len(known_names)>0:
    next_id = max(known_names) + 1
else:
    next_id = 1



print("processing unknown faces")

# For implementing multithreading, un-comment the next two lines

# webcam_stream = WebcamStream(stream_id="C:\\Users\\hai\\Desktop\\facerec\\stockvideo.mp4") # 0 id for main camera
# webcam_stream.start()

#2D array for stroing timestamps of corresponding IDs
times = {}


while True:

    #multithreading
    # uncomment the following and comment out the ret, image = video.read() line

    # if webcam_stream.stopped is True :
    #     break
    # else :
    #     image = webcam_stream.read()
    

    ret, image = video.read()
    

    # getting face locations and encodings
    locations = face_recognition.api.face_locations(image, model=MODEL)
    encodings = face_recognition.face_encodings(image, locations)

    for face_encoding, face_location in zip(encodings, locations):

        # Try to check if the detected face matches any known faces
        results = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)
        match = None

        # If it matches, add timestamp to previously known ID
        if True in results:
            match = known_names[results.index(True)]
            print("Match found: {match}",match)
            times[int(match[-1])].append(datetime.datetime.now())

        # If it does not match, create new ID in dictionary and store timestamp
        else:
            match = "ID"+str(next_id)
            next_id += 1
            known_names.append(match)
            known_faces.append(face_encoding)
            os.mkdir(f"{KNOWN_FACES_DIR}/{match}")
            pickle.dump(face_encoding, open(f"{KNOWN_FACES_DIR}/{match}/{match}-{int(time.time())}.pkl","wb"))
            times[int(match[-1])] = [datetime.datetime.now()]

        # coordinates to create the box around the face
        top_left = (face_location[3], face_location[0])
        bottom_right = (face_location[1], face_location[2])
        color = [0, 255, 0]
        cv2.rectangle(image, top_left, bottom_right, color, FRAME_THICKNESS)
        

        # Coordinates to put the text at the bottom of the rectangle
        top_left = (face_location[3], face_location[2])
        bottom_right = (face_location[1], face_location[2]+22)
        cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)
        cv2.putText(image, match,(face_location[3]+10, face_location[2]+15), cv2.FONT_HERSHEY_COMPLEX, 0.5, (200,200,200), FONT_THICKNESS)
    
    # Writing to output video file
    ########### CAUTION: VIDOE FILE IS OVERWRITTEN EVERY TIME THE PROGRAM IS RUN ############
    out.write(image)

    # CV2 can display the video file with the rectangles
    cv2.imshow("", image)

    # Print the times dictionary
    print(times)
    # break condition to get out of while loop.
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break
    


            







